{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8fa137",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br/>\n",
    "<img src=\"images/cd-logo-blue-600x600.png\" alt=\"\" width=\"130px\" align=\"left\"/>\n",
    "<img src=\"images/cd-logo-blue-600x600.png\" alt=\"\" width=\"130px\" align=\"right\"/>\n",
    "<div align=\"center\">\n",
    "<h2>Bootcamp Data Science - Módulo 3</h2><br/>\n",
    "<h1>Aprendizaje no supervisado</h1>\n",
    "<br/><br/>\n",
    "    <b>Instructor Principal:</b> Patricio Olivares polivares@codingdojo.la <br/>\n",
    "    <b>Instructor Asistente:</b> Daniela Blanco dblanco@codingdojo.la<br/><br/>\n",
    "    <b>Coding Dojo</b>\n",
    "</div>\n",
    "<br>\n",
    "Fuente: \"Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19951c3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algoritmos de aprendizaje supervisados vs no supervisados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae244761",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Aprendizaje supervisado\n",
    "\n",
    "- Algoritmo es guiado en el proceso de aprendizaje (se le indica qué debe aprender)\n",
    "- Ej:\n",
    "    - En algoritmo de regresión lineal, el modelo calcula parámetros que mejor se ajustan a datos conocidos\n",
    "- ¿Qué ocurre si no contamos con esta información?\n",
    "    - R: Algoritmos no supervisados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e314a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Aprendizaje no supervisado\n",
    "\n",
    "- No existe información previa sobre qué es lo que debe aprender el algoritmo\n",
    "- El algoritmo tiene libertad para aprender patrones de interés en los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10cce46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agrupamiento (Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3589ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Al igual que en clasificación, clustering asigna cada dato a un grupo\n",
    "- En el caso de clustering, los grupos **no son conocidos de antemano**\n",
    "\n",
    "<img src='images/clusteringExample.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b7b2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K-Means "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877da56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- K-Means permite agrupar datos a partir de un número **especificado** de clusters.\n",
    "- Para K-Means es necesario **especificar** el número de clusters de antemano. En algunos casos este número sera obvio, pero en otros no.\n",
    "- Cada clúster se marca inicialmente con un centroide. Este se va actualizando hasta ajustarse a las agrupaciones existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:,2:]\n",
    "y = iris.target\n",
    "\n",
    "fig = plt.figure(figsize=(13,4))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(X[y==0,0],X[y==0,1],'yo')\n",
    "ax1.plot(X[y==1,0],X[y==1,1],'bs')\n",
    "ax1.plot(X[y==2,0],X[y==2,1],'g^')\n",
    "ax1.legend(['Iris-Setosa','Iris-Versicolor','Iris-Virginica'])\n",
    "ax1.set_xlabel('Petal length')\n",
    "ax1.set_ylabel('Petal width')\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(X[:, 0],X[:,1],'k.')\n",
    "ax2.set_xlabel('Petal length')\n",
    "ax2.set_ylabel('Petal width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3444bad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Entrenamiento de K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 3 # Este es el número de agrupaciones (nuestro supuesto)\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "# OJO, no es que nos falte la división en training y test. NO es necesaria en este caso.\n",
    "kmeans.fit(X)\n",
    "\n",
    "y_pred = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec54e1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(13,4))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(X[y==0,0],X[y==0,1],'yo')\n",
    "ax1.plot(X[y==1,0],X[y==1,1],'bs')\n",
    "ax1.plot(X[y==2,0],X[y==2,1],'g^')\n",
    "ax1.legend(['Iris-Setosa','Iris-Versicolor','Iris-Virginica'])\n",
    "ax1.set_xlabel('Petal length')\n",
    "ax1.set_ylabel('Petal width')\n",
    "\n",
    "# Índice de agrupación cambia, pero agrupaciones se mantienen\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(X[y_pred==0,0],X[y_pred==0,1],'yo')\n",
    "ax2.plot(X[y_pred==1,0],X[y_pred==1,1],'g^')\n",
    "ax2.plot(X[y_pred==2,0],X[y_pred==2,1],'bs')\n",
    "# ax2.plot(X[y_pred==3,0],X[y_pred==3,1],'k*')\n",
    "ax2.set_xlabel('Petal length')\n",
    "ax2.set_ylabel('Petal width')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Score representa la inercia del modelo (distancia cuadrática media entre cada dato y su centroide)\n",
    "# Se muestra con valor negativo pues método score de scikit learn debe cumplir con\n",
    "# \"mayor valor, mejor\"\n",
    "print(kmeans.score(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab55a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Método del codo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e069003",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- En caso de no conocer el número de clusters, una buena aproximación es el método del codo\n",
    "- Se selecciona como número de clusters a aquel que produce **el último decremento \"importante\" en la inercia.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c7fd8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:,2:]\n",
    "\n",
    "score = []\n",
    "k_clusters = range(2,20) # Este range va de 2 a 20\n",
    "for k in k_clusters:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    score.append(-kmeans.score(X))\n",
    "    \n",
    "plt.plot(k_clusters, score,'b.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0f1c9",
   "metadata": {},
   "source": [
    "# Silhouette score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df357d",
   "metadata": {},
   "source": [
    "- Medida utilizada para determinar la separación entre clústeres, o en otras palabras, qué tan similar es cada muestra al resto de muestras de su clúster.\n",
    "- Mientras más cercano a 1, clúster se encuentran mejor separados y más compactos\n",
    "- Por cada muestra se calcula el coeficiente de silueta dado por la siguiente fórmula\n",
    "\n",
    "$$ \\frac{b-a}{\\text{max}(b,a)} $$\n",
    "\n",
    "donde $a$ es la distancia intra clúster y $b$ representa la distancia inter clúster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10f832",
   "metadata": {},
   "source": [
    "<img src='images/silueta.jpg' width=600>\n",
    "\n",
    "Fuente: https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57bfed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = []\n",
    "k_clusters = range(2,20) # Este range va de 1 a 20\n",
    "for k in k_clusters:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    score.append(silhouette_score(X, kmeans.labels_))\n",
    "plt.plot(k_clusters, score,'b.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52a960",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agrupamiento Jerárquico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d1a2d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Algoritmo que define jerarquía en los datos para generar agrupaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d582b1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Agrupamiento aglomerativo**: A partir de los datos individuales, se agrupan gradualmente hasta formar uno o mútiples grandes grupos. Aproximación *bottom up*.\n",
    "- **Agrupamiento divisional**: A partir de los datos agrupados, se dividen gradualmente hasta formar mútiples grupos pequeños. Aproximación *Up bottom*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d82907",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Escalamiento \"puede\" mejorar clusterings generados\n",
    "# # Escalamiento de datos \n",
    "# scaler = StandardScaler()\n",
    "# # Ajustar y transformar datos\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "agg_cluster = AgglomerativeClustering(n_clusters=3)\n",
    "y_pred = agg_cluster.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ee778",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96097dba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(13,4))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(X[y==0,0],X[y==0,1],'yo')\n",
    "ax1.plot(X[y==1,0],X[y==1,1],'bs')\n",
    "ax1.plot(X[y==2,0],X[y==2,1],'g^')\n",
    "ax1.legend(['Iris-Setosa','Iris-Versicolor','Iris-Virginica'])\n",
    "ax1.set_xlabel('Petal length')\n",
    "ax1.set_ylabel('Petal width')\n",
    "\n",
    "# Índice de agrupación cambia, pero agrupaciones se mantienen\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(X[y_pred==0,0],X[y_pred==0,1],'g^')\n",
    "ax2.plot(X[y_pred==1,0],X[y_pred==1,1],'yo')\n",
    "ax2.plot(X[y_pred==2,0],X[y_pred==2,1],'bs')\n",
    "ax2.set_xlabel('Petal length')\n",
    "ax2.set_ylabel('Petal width')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendograma (gráfico de conexiones de agrupamientos)\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "plt.figure(figsize = (15, 6))\n",
    "sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
    "plt.xlabel('Data Points');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca01e79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a97a1f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Density-based spatial clustering of applications with noise\n",
    "- Algoritmo capaz de identificar clúster de agrupación en base a la \"densidad\" de los datos.\n",
    "- Paso a paso:\n",
    "    - Por cada instancia, se cuentan cuántas instancias están dentro de una distancia $\\epsilon$ (vecindario $\\epsilon$)\n",
    "    - Si una instancia tienen al menos `min_samples` instancias en su vecindario, es considerada una instancia `core`.\n",
    "    - Todas las instancias en el vecindario de una instancia core pertenecen al mismo clúster (incluídas otras instancias core).\n",
    "    - Cualquier instancia que no sea una instancia core o no pertenezca a un vecindario, es considerada anomalía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e61ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:,2:]\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "y_pred = dbscan.fit_predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd156ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(13,4))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.plot(X[y==0,0],X[y==0,1],'yo')\n",
    "ax1.plot(X[y==1,0],X[y==1,1],'bs')\n",
    "ax1.plot(X[y==2,0],X[y==2,1],'g^')\n",
    "ax1.legend(['Iris-Setosa','Iris-Versicolor','Iris-Virginica'])\n",
    "ax1.set_xlabel('Petal length')\n",
    "ax1.set_ylabel('Petal width')\n",
    "\n",
    "# Índice de agrupación cambia, pero agrupaciones se mantienen\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.plot(X[y_pred==-1,0],X[y_pred==-1,1],'r*') # Anomalías\n",
    "ax2.plot(X[y_pred==0,0],X[y_pred==0,1],'yo')\n",
    "ax2.plot(X[y_pred==1,0],X[y_pred==1,1],'bs')\n",
    "ax2.plot(X[y_pred==2,0],X[y_pred==2,1],'g^')\n",
    "# ax2.plot(X[y_pred==3,0],X[y_pred==3,1],'k.')\n",
    "ax2.legend(['Anomalías', 'Iris-Setosa','Iris-Versicolor','Iris-Virginica'])\n",
    "ax2.set_xlabel('Petal length')\n",
    "ax2.set_ylabel('Petal width')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba661a96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Actividad 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847f5ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Scikit Learn no solo provee algunos datasets populares. También incluye `toy datasets`, los cuales son datasets para comprobar las particularidades de distintos modelos.\n",
    "\n",
    "- Estudie el toy dataset Make Moons disponible en scikit learn [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html)\n",
    "- Genere un dataset con 1000 muestras y ruido (noise) $0.05$.\n",
    "- Utilice los distintos algoritmos de clustering para identificar agrupaciones de datos. Utilice matplotlib para mostrar gráficamente cuál de ellos se ajusta mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a3261",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "#codigo extra, para que imagenes de matplotlib\n",
    "#estén centradas en las diapositivas, ejecutar antes de lanzar los ejemplos."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
